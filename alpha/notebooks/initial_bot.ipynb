{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retrieve_relevant_docs import RetrieveRelevantDocs\n",
    "\n",
    "from langchain.llms import CTransformers\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"L:\\job\\CV\\Lalith Sagar Devagudi_cv_02012024.pdf\"\n",
    "rrds = RetrieveRelevantDocs(pdf_path)\n",
    "query = \"What is the email id?\"\n",
    "retrieved_documents = rrds.get_relevant_docs(query, n_results=2)\n",
    "print(\"Query------------------:\", query)\n",
    "for document in retrieved_documents:\n",
    "    print(\"====================================\\n\", document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    messages= [{\"role\": \"system\", \"content\": \"You are a text extractor and extract the answer for the question from the given context. Keep answers concise and to the point.\"},\n",
    "              {\"role\": \"user\", \"content\": \"context:\"+retrieved_documents[0][1]+\"\\nquestion:\"+query+\"\\nanswer:\"},\n",
    "\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    max_tokens=150,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = CTransformers(model='.\\..\\llms\\llama-2-7b-chat.Q2_K.gguf', model_type='llama2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = CTransformers(model='.\\..\\llms\\mistral-7b-instruct-v0.1.Q2_K.gguf', model_type='mistral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_prompt = \"\"\"[INST] <<SYS>>\\nYou are a text extractor and extract the answer for the question from the given context. Keep answers concise and to the point.\"\"\"\n",
    "context_section = \"Context: {context}\\n\"\n",
    "question_section = \"Question: {question}\"\n",
    "response_section = \"[/INST]\"\n",
    "\n",
    "template = pre_prompt + context_section + question_section + response_section\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Providing a context (can be an empty string if context is not relevant)\n",
    "context = \"Yashwanth Tadakamalla ne49 17647603884 yashwanthtadakamallagmailcom nednYashwanth Tadakamalla gtbYashwanth gbePortfolio Paderborn Germany About me A creative pragmatic Data Science enthusiast who is familiar with the processes for gathering cleaning and organizing data to support the companys transformation into a datadriven business model Advanced understanding of statistical and machine learning techniques and experience in identifying opportunities and strategizing methods for improvement Work Experience Ernst Young Nov 2021 July 2023 Technology Consultant Intern D usseldorf Germany Spearheaded exploratory data analysis contributing to the training testing and implementation of a BERT model for automatic job requirements and resume matching Conducted meticulous data labeling and cleaning elevating data quality and significantly enhancing the accuracy of subsequent analyses and models Independently designed and deployed a Chatbot using Power Virtual Agent Showcased expertise in AI through various demonstrations such as creating an automatic codecommenting system and an interview bot utilizing the OpenAI API Ensured comprehensive project documentation documenting all software development processes and results for future reference and knowledge sharing SayCheese Jan 2019 June 2019 Data Analyst Hyderabad India Employed descriptive and diagnostic analysis to identify patterns and predict likely outcomes Prepared and delivered reports to management using PowerBI providing valuable insights from data analysis Projects Master Thesis Reconfigurable FPGA Layout Generation Python Optimization algorithms May 2023 Developed and implemented novel Simulated Annealing and Evolutionary Strategy algorithms to efficiently solve the layout generation problem based on microslots Conducted an extensive comparative analysis of the performance and effectiveness of SA and ES algorithms in generating optimal layouts Addressed challenges of layout generation with innovative layout generation solutions Evaluated algorithm performance against existing Heuristic and Optimal solutions based on FPGA utilization and runtime Semantic Matching with German BERT for CV AFO Matching Python NLP EDA June 2022 Led CV matching application development utilizing semantic matching with a German BERT model for effective job requirement matching Conducted insightful exploratory data analysis EDA to understand data and its nature Ensured precise data cleaning and loading rigorous model training and testing for enhanced performance CV Named Entity Recognition NER Python NLP Data Labelling Data Modelling January 2022 Significantly contributed to an advanced system using Spacy and NLTK for accurate Named Entity Recognition NER in resumes facilitating efficient skills and role categorization Led comprehensive data cleaning and precise text labeling ensuring highquality input for the system Collaborated within an agile team ensuring timely project execution and success Comment Your Code Python Prompt Engineering API June 2023 Developed an AIpowered chatbot leveraging prompt engineering and the GPT API Users upload Python py files containing functions and the chatbot automatically generates descriptive comments for each function Utilized prompt engineering to prompt the GPT API to create explanatory comments above functions within the uploaded py files This automation significantly enhances code documentation and readability The chatbots automated comment generation contributes to code quality by ensuring clear and consistent documentation of function purpose and usage fostering better code maintenance and team collaboration Interview Bot AIdriven Interview Process Python Prompt Engineering Streamlight API June 2023 Applied advanced prompt engineering techniques to optimize Interview Bot for contextually relevant interview questions Seamlessly integrated the GPT API as the projects natural language generation engine enabling dynamic and personalized question generation based on job descriptions Employed the GPT API to assess user responses against job descriptions facilitating realtime feedback and suitability valuations Interactive Sales Dashboard PowerBI SAC May 2020 Identified key performance indicators KPIs relevant to sales such as revenue sales growth customer acquisition and product performance Designed an intuitive and visually appealing dashboard layout ensuring easy navigation and data interpretation Implemented interactive filters and slicers to allow users to customize the dashboard view based on specific criteria BATMANWeb App for Autonomous Car Threat Analysis Python Spacy BERT EDA May 2020 Developed a web app using language models spaCy BERT XLNet for autonomous car developers to analyze threats consequences and solutions Gathered cleaned and organized data with a focus on XLNet implementation and utilization Education Paderborn University 2019 2023 Informatic Master PaderbornNRWGermany Interactive Data Visualization ModelBased Systems EngineeringHighPerformance Computing Machine Learning Software Quality AssuranceDesign and Code analysis Advanced Computer Architecture Technical Skills Programming Languages Python R SQL Scala Tools Power BI Power Query CICD PowerApps MS Office MS Excel Git Apache Spark Big Data tools Microsoft Azure Google Cloud Streamlit Docker Agile Project Management Jupyter Notebook Machine Learning Time Series Analysis Computational Argumentation NLP language models BERT spaCy Large Language Models LLM Pandas Numpy Pytorch Tensorflow Scikit learn Keras Apache Spark Data Analysis and Visualization Data Mining Data Modeling Data Preprocessing Image Classification Exploratory Data Analysis EDA Tableau Dashboard Creation Matplotlib Seaborn Web Development HTML CSS Flask Languages German Intermediate English Fluent\"  # Add context here if needed\n",
    "\n",
    "# The question you want to ask\n",
    "question = \"How is the protagonist of the movie?\"\n",
    "\n",
    "# Running the LLMChain with both context and question\n",
    "response = llm_chain.run({\"context\": context, \"question\": question})\n",
    "\n",
    "# Splitting the response into lines\n",
    "response_lines = response.split(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  The protagonist of the movie Guntur Kaaram is Mahesh Babu, as mentioned in the context.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llama2 response\n",
    "response_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' The protagonist of the movie is Mahesh Babu.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mistral response\n",
    "response_lines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
